{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0986406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linprog, minimize_scalar\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0b3329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.01\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03ddd0",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "In matrix form for $Z = (z_1, ..., z_n) \\in \\mathbb{R}^{d\\times n}$ this reads\n",
    "\\begin{equation*}\n",
    "    Y = Q^* X (P^*)^\\top + \\sigma Z\n",
    "\\end{equation*}\n",
    "where $P^*_{ij} = \\mathbb{1}_{\\pi^*(i) = j}$. To see that this corresponds to (1), note that $$\n",
    "\\left(X(P^*)^\\top\\right)_{ij}= \\sum_{k=1}^n X_{ik} P^*_{jk} = \\sum_{k=1}^n X_{ik} \\mathbb{1}_{\\pi^*(j) = k} = X_{i, \\pi^*(j)} \\quad \\implies \\quad \\left(X(P^*)^\\top\\right)_{\\bullet j} = x_{\\pi^*(j)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ec4a3",
   "metadata": {},
   "source": [
    "# Optimisation algorithms\n",
    "\n",
    "### Frank Wolfe\n",
    "\n",
    "We need to use Frank-Wolfe for solving\n",
    "$$\n",
    "D^* = \\underset{D \\in \\mathcal{D}_n}{\\mathrm{argmin}} \\, \\Vert AD - DB \\Vert_F^2\n",
    "$$\n",
    "where $A = X^TX$, $B = Y^\\top Y$, and\n",
    "$$\n",
    "\\mathcal{D}_n = \\left\\{ D \\in \\mathbb{R}^{n\\times n} \\, : \\, \\sum_{i = 1}^n D_{ij} = 1 \\text{ and } \\sum_{j = 1}^n D_{ij} = 1 \\right\\}.\n",
    "$$\n",
    "\n",
    "For this, define\n",
    "$$\n",
    "    f: \\mathbb{R}^{n^2} \\to \\mathbb{R}, \\, D = (d_{ij})_{i, j = 1}^n \\, \\mapsto \\, \\Vert AD - DB \\Vert_F^2\n",
    "$$\n",
    "and realise that $f$ is differentiable as well as convex. Furthermore, the set $\\mathcal{D}_n$ is convex and compact. We will generate a sequence $D_i$ converging to $D^*$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e409e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frank_wolfe(D_init, X, Y, step_max, stepsize, A_eq, b_eq, tol=0.1, verbose=0):\n",
    "    if verbose>0: print(\"Starting Frank-Wolfe with \"+str(step_max)+ \" steps...\")\n",
    "    D = D_init.copy()\n",
    "    if step_max == 0: return D\n",
    "    n = len(D)\n",
    "    if verbose>0: print(\"Value of f before iterations = \"+str(f(D, X, Y)))\n",
    "    step = 1\n",
    "    while True:\n",
    "        if verbose>1: print(\"FW step no \"+str(step))\n",
    "        G = (grad_f(D, X, Y)).flatten()\n",
    "        S_hat = perm_projection(G, A_eq, b_eq)\n",
    "        Direction = S_hat - D\n",
    "        # Line search\n",
    "        gamma = minimize_scalar(\n",
    "            lambda gamma:f(D + gamma*Direction), \n",
    "            bounds=(0,1), \n",
    "            method='bounded').x\n",
    "        \n",
    "        D = D + gamma*Direction\n",
    "#         D = D + stepsize*Direction\n",
    "#         D = D + (2/(step + 1))*Direction\n",
    "        if step == step_max:\n",
    "                if verbose>0: print(\"Reached max number of iterations.\")\n",
    "                break\n",
    "        step += 1\n",
    "    if verbose>0: \n",
    "        print(\"Value of f at convergence = \"+str(f(D, X, Y)))\n",
    "        print(\"Finished Frank-Wolfe...\")\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64087191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pingpong(Pinit, Pstar, Qstar, X, Y, A_eq, b_eq, plot=True, verbose=0):\n",
    "    loss_errs = []\n",
    "    orth_errs = []\n",
    "    perm_errs = []\n",
    "    my_xticks = []\n",
    "\n",
    "    pindex = 0\n",
    "    qindex = 0\n",
    "    P_turn = False\n",
    "    n = len(X[0])\n",
    "    d = len(X)\n",
    "    lastP = np.zeros((n, n))\n",
    "    lastQ = np.zeros((d, d))\n",
    "    P = Pinit.copy()\n",
    "    Q = np.ones((d, d))\n",
    "    \n",
    "    if verbose>0: print(\"Starting PingPong...\")\n",
    "\n",
    "    while np.linalg.norm(lastP-P) > 0 and np.linalg.norm(lastQ-Q) > 0:\n",
    "        if P_turn:\n",
    "            if verbose>1: print(str(is_permutation(P)) + str(np.linalg.norm(lastP-P)))\n",
    "            pindex += 1\n",
    "            lastP = P\n",
    "            P = perm_from_ortho(Q, X, Y, A_eq, b_eq)\n",
    "            P_turn = False\n",
    "        else:\n",
    "            qindex += 1\n",
    "            lastQ = Q\n",
    "            Q = ortho_from_perm(P, X, Y)\n",
    "            P_turn = True\n",
    "        loss_errs.append(empirical_loss(X, Y, P, Q)**2)\n",
    "        perm_errs.append(L2perm_squared(P, Pstar, X))\n",
    "        orth_errs.append(L2ortho_squared(Q, Qstar))\n",
    "        my_xticks.append(\"(P\"+str(pindex)+\", Q\"+str(qindex)+\")\")\n",
    "    if verbose>0: print(\"Finished PingPong. Loss at convergence equals: \" + str(empirical_loss(X, Y, P, Q)))\n",
    "    if verbose>0: print(\"Loss at optimum (P*, Q*) equals: \" + str(empirical_loss(X, Y, Pstar, Qstar)))\n",
    "\n",
    "    if plot:\n",
    "        xs = range(len(ys))\n",
    "        plt.plot(xs, loss_errs, label=\"||QX - YX||^2\")\n",
    "        plt.plot(xs, orth_errs, label=\"||Q - Q*||^2\")\n",
    "        plt.plot(xs, perm_errs, label=\"||XP.T - XP*.T||^2\")\n",
    "        plt.xticks(xs, my_xticks)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return overlap(P, Pstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d4860",
   "metadata": {},
   "source": [
    "\n",
    "# Experiments\n",
    "\n",
    "Here, we try the above functions for different values of $n$, $d$ and $\\sigma$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c899803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(optim_function, \n",
    "               n, d, sigma, \n",
    "               P0_steps, \n",
    "               stepsize,\n",
    "               tol=0.1,\n",
    "               verbose=0, \n",
    "               pingpong_plot=False,\n",
    "               init_plot=False,\n",
    "               seed_XYZ = 1234\n",
    "              ):\n",
    "    # Setup\n",
    "    A_eq, b_eq = equality_constraints(n)\n",
    "    X, Y, Pstar, Qstar = initialise_XYPstarQstar(n, d, sigma, \n",
    "                                                 init_plot, \n",
    "                                                 seed_XYZ)\n",
    "    # Find P0\n",
    "    D_init = (1/n)*np.ones((n, n))\n",
    "    P0 = optim_function(D_init,\n",
    "                        X, Y, \n",
    "                        P0_steps, \n",
    "                        stepsize, \n",
    "                        A_eq, b_eq, \n",
    "                        tol,\n",
    "                        verbose)\n",
    "    # PingPong\n",
    "    overlap = pingpong(P0, \n",
    "                       Pstar, Qstar, \n",
    "                       X, Y, A_eq, b_eq, \n",
    "                       pingpong_plot, \n",
    "                       verbose\n",
    "                      )\n",
    "    # Report results\n",
    "    print(\"Overlap=\" + str(overlap) \n",
    "          + \" for \"+str(optim_function.__name__)\n",
    "          +\" with n=\"+str(n)\n",
    "          +\", d=\"+str(d)\n",
    "          +\", sig=\"+str(sigma) \n",
    "          +\", P0_steps=\"+(\"0\" if P0_steps<10 else \"\")+str(P0_steps)\n",
    "          +\", stepsize=\"+str(stepsize)\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2233f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- d=10, sigma=0.05 -----\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input for linprog: unable to interpret bounds with this dimension tuple: (100000000, 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bm/nzzlls4n7qb83n1ks8938fm1fkqzyf/T/ipykernel_87385/1630009509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mstepsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrank_wolfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP0_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/bm/nzzlls4n7qb83n1ks8938fm1fkqzyf/T/ipykernel_87385/2182583139.py\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(optim_function, n, d, sigma, P0_steps, stepsize, tol, verbose, pingpong_plot, init_plot, seed_XYZ)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Find P0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mD_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     P0 = optim_function(D_init,\n\u001b[0m\u001b[1;32m     19\u001b[0m                         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mP0_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/nzzlls4n7qb83n1ks8938fm1fkqzyf/T/ipykernel_87385/4245536473.py\u001b[0m in \u001b[0;36mfrank_wolfe\u001b[0;34m(D_init, X, Y, step_max, stepsize, A_eq, b_eq, tol, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FW step no \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mS_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperm_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_eq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mDirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Line search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/CloudStorage/Dropbox/Inria/procrustes-wasserstein/Algorithm/functions.py\u001b[0m in \u001b[0;36mperm_projection\u001b[0;34m(M, A_eq, b_eq)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Minimize over bistochastic matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mMflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinprog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_eq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_eq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_eq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linprog.py\u001b[0m in \u001b[0;36mlinprog\u001b[0;34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0, integrality)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LPProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_ub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_eq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintegrality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_linprog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m     \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tol'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linprog_util.py\u001b[0m in \u001b[0;36m_parse_linprog\u001b[0;34m(lp, options, meth)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                                       lp.A_ub, lp.A_eq)\n\u001b[1;32m   1003\u001b[0m     \u001b[0;31m# Convert lists to numpy arrays, etc...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clean_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_ub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_ub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_eq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_eq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linprog_util.py\u001b[0m in \u001b[0;36m_clean_inputs\u001b[0;34m(lp)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \"not a 2 x {:d} array.\".format(n_x, n_x))\n\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0;34m\"Invalid input for linprog: unable to interpret bounds with this \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \"dimension tuple: {0}.\".format(bsh))\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid input for linprog: unable to interpret bounds with this dimension tuple: (100000000, 2)."
     ]
    }
   ],
   "source": [
    "for sigma in [0.05, 0.1, 0.2]:\n",
    "    for d in [10, 20, 50]:\n",
    "        print(\"----- d=\"+str(d)+ \", sigma=\"+str(sigma)+\" -----\")\n",
    "        for P0_steps in [1, 20, 100, 1000]:\n",
    "            n = 100\n",
    "            stepsize = 1/100\n",
    "            experiment(frank_wolfe, n, d, sigma, P0_steps, stepsize, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Birkhoff_projection(M):\n",
    "    # Projects matrix onto the closest doubly stochastic matrix\n",
    "    ...\n",
    "\n",
    "def projected_gradient_descent(D_init, X, Y, step_max, stepsize, A_eq, b_eq, tol=0.1, verbose=1):\n",
    "    if verbose>0: print(\"Running Projected Gradient Descent with \"+str(step_max)+ \" iterations and step size \"+str(stepsize))\n",
    "    D = D_init.copy()\n",
    "    if step_max == 0: return D\n",
    "    n = len(D)\n",
    "    if verbose>0: print(\"Loss value before iterations = \"+str(f(D, X, Y)))\n",
    "    step = 1\n",
    "    while True:\n",
    "        if verbose>1:print(\"Projected GD step no. \"+str(step))\n",
    "        G = grad_f(D, X, Y)\n",
    "        D = D - stepsize*G\n",
    "        \n",
    "#         D = Birkhoff_projection(D, A_eq, b_eq)\n",
    "        \n",
    "        if step == step_max:\n",
    "                if verbose>0: print(\"Reached max number of iterations.\")\n",
    "                break\n",
    "        step += 1\n",
    "    if verbose>0: print(\"Loss value after iterations = \"+str(f(D, X, Y)))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "d=15\n",
    "sigma=0.4\n",
    "steps=50\n",
    "stepsize=1/50\n",
    "\n",
    "evaluate_convergence(frank_wolfe, n, d, sigma, steps, stepsize)\n",
    "evaluate_convergence(projected_gradient_descent, n, d, sigma, steps, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b969c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab100ff9",
   "metadata": {},
   "source": [
    "# Augmentation via belief propagation\n",
    "This seems already better now. Let's try to augment the solution since we're super far from the true one.\n",
    "\n",
    "Other Todos: \n",
    "- Reimplement the stuff from Berthet paper and see how we're doing\n",
    "- Do the descent from Berthet and see how it compares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5123b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tronc_lines = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    j = np.argmax(D[i, :])\n",
    "    tronc_lines[i,j] = 1\n",
    "    \n",
    "plt.imshow(tronc_lines, cmap='hot')\n",
    "plt.title(\"Keeping only maximising index of each line in D\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss trajectory when initialising with max line element\")\n",
    "P, Q = augment_PandQ(X, Y, tronc_lines, A_eq, b_eq)\n",
    "print(empirical_loss(X, Y, P, Q))\n",
    "for i in range(4):\n",
    "    P, Q = augment_PandQ(X, Y, P, A_eq, b_eq)\n",
    "    print(loss(X, Y, P, Q))\n",
    "print(\"Loss at (P*, Q*) equals: \" + str(empirical_loss(X, Y, Pstar, Qstar)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0ef23",
   "metadata": {},
   "source": [
    "# Archive, code not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb52e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Histograms for the doubly stochastic matrix\")\n",
    "\n",
    "\n",
    "vecD = D.flatten()\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(vecD, bins=50, rwidth = 0.7)\n",
    "plt.title(\"histogram values in vecD, LOGSCALE\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "n_plots = 5\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "for i in range(n_plots):\n",
    "    plt.subplot(n_plots, 2, 2*i+1)\n",
    "    plt.hist(vecD[i*n:(i+1)*n], bins=50, rwidth = 0.7)\n",
    "    plt.title(\"Histogram of LINE number \" +str(i+1)+\" of D\")\n",
    "    plt.yscale(\"log\")\n",
    "    \n",
    "    plt.subplot(n_plots, 2, 2*i+2)\n",
    "    plt.hist(vecD[i::n], bins=50, rwidth = 0.7, color=\"red\")\n",
    "    plt.title(\"Histogram of COLUMN number \" +str(i+1)+\" of D\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4549c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "P0 = perm_projection(D, A_eq, b_eq)\n",
    "P, Q = augment_PandQ(X, Y, P0, A_eq, b_eq)\n",
    "print(\"Loss trajectory for initialisation at P0 = Proj_Perm(D)\")\n",
    "print(empirical_loss(X, Y, P, Q))\n",
    "for i in range(6):\n",
    "    P, Q = augment_PandQ(X, Y, P, A_eq, b_eq)\n",
    "    print(empirical_loss(X, Y, P, Q))\n",
    "print(\"Loss at (P*, Q*) equals: \" + str(empirical_loss(X, Y, Pstar, Qstar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other matrices to check out the alternative optim algo.\n",
    "pirand = np.random.permutation(n)\n",
    "Prand = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if pirand[i] == j:\n",
    "            Prand[i,j] = 1\n",
    "            \n",
    "PprojD = perm_projection(D, A_eq, b_eq)\n",
    "\n",
    "D_tronc_lines = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    j = np.argmax(D[i, :])\n",
    "    D_tronc_lines[i,j] = 1\n",
    "print(\"Defined Prand, PprojD, D_tronc_lines\")\n",
    "pingpong(Prand, X, Y, A_eq, b_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755594c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae45214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7810e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
